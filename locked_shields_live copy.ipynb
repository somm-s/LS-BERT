{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Live Locked Shields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "configuration = \"fi-100_ft-15000000_nb-30_ht-100000_di-uni_mx-1500_lg-no\"\n",
    "dataset_path = \"datasets\"\n",
    "model_path = \"trained_models/fine_tune_all_years_ded_coa_med_seq-128_old_\" + configuration + \"/finetuned_model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "ip_documents = {}\n",
    "\n",
    "def get_next_sentence_pairs(document_path):    \n",
    "    labelled_sentence_pairs = []\n",
    "    file_list = os.listdir(document_path)\n",
    "    for file in file_list:\n",
    "        with open(document_path + \"/\" + file, 'r') as f:\n",
    "            ip1 = file.split(\".txt\")[0]\n",
    "            if ip1 in ip_documents:\n",
    "                position = ip_documents[ip1][\"position\"]\n",
    "                f.seek(position)\n",
    "                lines = f.readlines()\n",
    "                ip_documents[ip1][\"position\"] = f.tell()\n",
    "            else:\n",
    "                lines = f.readlines()\n",
    "                ip_documents[ip1] = {\"position\": f.tell()}\n",
    "                        \n",
    "            for line in lines:\n",
    "                line.strip()\n",
    "                ip2, start_time, end_time, sentence = line.split(\",\")\n",
    "                last_sentence = None\n",
    "                if ip2 in ip_documents[ip1]:\n",
    "                    last_sentence = ip_documents[ip1][ip2]\n",
    "                    ip_documents[ip1][ip2] = sentence\n",
    "                    labelled_sentence_pairs.append((last_sentence, sentence, ip1, ip2, start_time, end_time))\n",
    "                else:\n",
    "                    ip_documents[ip1][ip2] = sentence\n",
    "                    labelled_sentence_pairs.append((sentence, \"3 \\n\", ip1, ip2, start_time, end_time))\n",
    "                    \n",
    "    return labelled_sentence_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bert_inference_dataset import *\n",
    "\n",
    "sentence_pairs = get_next_sentence_pairs(\"ls24_live_dataset/exploration_full\")\n",
    "data = BERTInferenceDataset(sentence_pairs, seq_length=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluate_bert import *\n",
    "model_path = \"trained_models/fine_tune_all_years_ded_coa_med_seq-128_old_fi-100_ft-15000000_nb-30_ht-100000_di-uni_mx-1500_lg-no/finetuned_model\"\n",
    "embeddings = get_embeddings(model_path, data, batch_size=1024, resample=False, use_labels=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluate_bert import *\n",
    "visualize_embeddings([embeddings], [\"All Traffic\"], \"Embeddings during Exploration\", method=\"tsne\", sample=20000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rt_ip_list = []\n",
    "with open(\"rt_24_ips.txt\", \"r\") as f:\n",
    "    rt_ip_list = f.readlines()\n",
    "    rt_ip_list = [ip.strip() for ip in rt_ip_list]\n",
    "rt_ips = set(rt_ip_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rt_embeddings = []\n",
    "rt_metadata = []\n",
    "rt_data = []\n",
    "other_embeddings = []\n",
    "other_metadata = []\n",
    "other_data = []\n",
    "\n",
    "for embedding, meta, d in zip(embeddings, data.metadata, data):\n",
    "    ip1, ip2, start_time, end_time = meta\n",
    "    if ip1 in rt_ips:\n",
    "        rt_embeddings.append(embedding)\n",
    "        rt_metadata.append(meta)\n",
    "        rt_data.append(d)\n",
    "    else:\n",
    "        other_embeddings.append(embedding)\n",
    "        other_metadata.append(meta)\n",
    "        other_data.append(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to numpy array\n",
    "rt_embeddings = np.array(rt_embeddings)\n",
    "other_embeddings = np.array(other_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate cosine similarities between rt and other\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "cosine_similarities = cosine_similarity(rt_embeddings, other_embeddings)\n",
    "\n",
    "print(cosine_similarities.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get top 5 that are most similar to rt on average\n",
    "top_5 = np.argsort(np.mean(cosine_similarities, axis=0))[::-1][:50]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print ips of top 5 and their score\n",
    "for i in top_5:\n",
    "    print(other_metadata[i], np.mean(cosine_similarities[:, i]))\n",
    "    print(other_data[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluate_bert import *\n",
    "visualize_embeddings([other_embeddings, rt_embeddings], [\"Classified as Malicious\", \"Classified as Benign\"], \"Embeddings during Exploration by Classification\", method=\"tsne\", sample=20000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "svm = joblib.load(\"svm_model.pkl\")\n",
    "\n",
    "batch_size = 5000\n",
    "bt_embeddings = []\n",
    "rt_embeddings = []\n",
    "labels = []\n",
    "for i in range(0, embeddings.shape[0], batch_size):\n",
    "    print(\"Processing embedding \", i, \" of \", embeddings.shape[0])\n",
    "    predictions = svm.predict_proba(embeddings[i:i+batch_size])[:,1]\n",
    "    y_pred_batch = (predictions >= 0.01).astype(int)\n",
    "    rt_embeddings_batch = embeddings[i:i+batch_size][y_pred_batch == 0]\n",
    "    bt_embeddings_batch = embeddings[i:i+batch_size][y_pred_batch == 1]\n",
    "    \n",
    "    labels.extend(y_pred_batch)\n",
    "    rt_embeddings.extend(rt_embeddings_batch)\n",
    "    bt_embeddings.extend(bt_embeddings_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\"external_host\", \"internal_host\", \"start_time\", \"end_time\", \"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\"external_host\", \"internal_host\", \"start_time\", \"end_time\", \"label\"]\n",
    "file_name = \"ls24_live_dataset/predictions.csv\"\n",
    "all_data_file_name = \"ls24_live_dataset/all_data.csv\"\n",
    "\n",
    "with open(file_name, 'a') as f:\n",
    "    with open(all_data_file_name, 'a') as f2:\n",
    "        for label, metadata in zip(labels, data.metadata):\n",
    "            if label == 0:\n",
    "                ip1, ip2, start_time, end_time = metadata\n",
    "                f2.write(ip1 + \",\" + ip2 + \",\" + start_time + \",\" + end_time + \"\\n\")\n",
    "                f.write(ip1 + \",\" + ip2 + \",\" + start_time + \",\" + end_time + \",0\" + \"\\n\")\n",
    "            else:\n",
    "                ip1, ip2, start_time, end_time = metadata\n",
    "                f2.write(ip1 + \",\" + ip2 + \",\" + start_time + \",\" + end_time + \",1\" + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(file_name, names=columns[:4])\n",
    "# read top 10 most appearing external hosts\n",
    "top_external_hosts = df[\"external_host\"].value_counts().head(30)\n",
    "top_external_hosts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'similarity_dataset' from '/cluster/raid/home/sosi/repos/Bert/similarity_dataset.py'>"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "import similarity_dataset\n",
    "importlib.reload(similarity_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "from similarity_dataset import SimilarityDataset\n",
    "data_2021 = SimilarityDataset(2021, fine=True, label_path=\"ip_labels_2021.txt\", only_rt=False)\n",
    "data_2022 = SimilarityDataset(2022, fine=True, label_path=\"ip_labels_2022.txt\", only_rt=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "X_rt_21, X_rt_ip_21 = data_2021.get_rt_host_embeddings()\n",
    "X_b_21, X_b_ip_21 = data_2021.get_benign_host_embeddings()\n",
    "X_rt_22, X_rt_ip_22 = data_2022.get_rt_host_embeddings()\n",
    "X_b_22, X_b_ip_22 = data_2022.get_benign_host_embeddings()\n",
    "XX_rt_21, XX_rt_ip_21 = data_2021.get_rt_host_host_embeddings()\n",
    "XX_b_21, XX_b_ip_21 = data_2021.get_benign_host_host_embeddings()\n",
    "XX_rt_22, XX_rt_ip_22 = data_2022.get_rt_host_host_embeddings()\n",
    "XX_b_22, XX_b_ip_22 = data_2022.get_benign_host_host_embeddings()\n",
    "\n",
    "X_21 = np.concatenate([X_rt_21, X_b_21])\n",
    "y_21 = np.concatenate([np.ones(X_rt_21.shape[0]), np.zeros(X_b_21.shape[0])])\n",
    "X_22 = np.concatenate([X_rt_22, X_b_22])\n",
    "y_22 = np.concatenate([np.ones(X_rt_22.shape[0]), np.zeros(X_b_22.shape[0])])\n",
    "XX_21 = np.concatenate([XX_rt_21, XX_b_21])\n",
    "yy_21 = np.concatenate([np.ones(XX_rt_21.shape[0]), np.zeros(XX_b_21.shape[0])])\n",
    "XX_22 = np.concatenate([XX_rt_22, XX_b_22])\n",
    "yy_22 = np.concatenate([np.ones(XX_rt_22.shape[0]), np.zeros(XX_b_22.shape[0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((576, 512),\n",
       " (576,),\n",
       " (27344, 512),\n",
       " (27344,),\n",
       " (17712, 512),\n",
       " (17712,),\n",
       " (373472, 512),\n",
       " (373472,))"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_21.shape, y_21.shape, X_22.shape, y_22.shape, XX_21.shape, yy_21.shape, XX_22.shape, yy_22.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7950550986319069\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      1.00      0.98      5241\n",
      "         1.0       0.98      0.28      0.44       228\n",
      "\n",
      "    accuracy                           0.97      5469\n",
      "   macro avg       0.98      0.64      0.71      5469\n",
      "weighted avg       0.97      0.97      0.96      5469\n",
      "\n",
      "0.7952184989222026\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      1.00      0.99       567\n",
      "         1.0       0.00      0.00      0.00         9\n",
      "\n",
      "    accuracy                           0.98       576\n",
      "   macro avg       0.49      0.50      0.50       576\n",
      "weighted avg       0.97      0.98      0.97       576\n",
      "\n",
      "0.7811811180034491\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      1.00      0.99     19430\n",
      "         1.0       1.00      0.19      0.32       570\n",
      "\n",
      "    accuracy                           0.98     20000\n",
      "   macro avg       0.99      0.60      0.65     20000\n",
      "weighted avg       0.98      0.98      0.97     20000\n",
      "\n",
      "0.3075921247495427\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00     17660\n",
      "         1.0       0.00      0.00      0.00        52\n",
      "\n",
      "    accuracy                           1.00     17712\n",
      "   macro avg       0.50      0.50      0.50     17712\n",
      "weighted avg       0.99      1.00      1.00     17712\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cluster/raid/home/sosi/repos/Bert/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/cluster/raid/home/sosi/repos/Bert/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/cluster/raid/home/sosi/repos/Bert/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "def train_model(X, y, model, split_size=0.2):\n",
    "    if X.shape[0] > 100000:\n",
    "        idx = np.random.choice(X.shape[0], 100000, replace=False)\n",
    "        X = X[idx]\n",
    "        y = y[idx]\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=split_size, random_state=42, stratify=y)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict_proba(X_test)[:,1]\n",
    "    print(roc_auc_score(y_test, y_pred))\n",
    "    print(classification_report(y_test, y_pred >= 0.5))\n",
    "    model.fit(X, y)\n",
    "    return model\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=100, max_depth=10, n_jobs=-1)\n",
    "clf = train_model(X_22, y_22, model)\n",
    "\n",
    "# store classifer\n",
    "import joblib\n",
    "joblib.dump(clf, \"rf_host_model_22.pkl\")\n",
    "\n",
    "y_pred = clf.predict_proba(X_21)[:,1]\n",
    "print(roc_auc_score(y_21, y_pred))\n",
    "print(classification_report(y_21, y_pred >= 0.5))\n",
    "\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=100, max_depth=10, n_jobs=-1)\n",
    "clf = train_model(XX_22, yy_22, model)\n",
    "\n",
    "joblib.dump(clf, \"rf_host_host_model_22.pkl\")\n",
    "\n",
    "y_pred = clf.predict_proba(XX_21)[:,1]\n",
    "\n",
    "print(roc_auc_score(yy_21, y_pred))\n",
    "print(classification_report(yy_21, y_pred >= 0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
